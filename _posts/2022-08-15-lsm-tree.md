---
layout: post
title:  "LSM-Tree"
author: "marcelyz"
---

- 问：LSM-Tree中的读放大、写放大、空间放大  
答：LSM-Tree能将离散的随机写请求都转换成批量的顺序写请求(WAL + Compaction)，以此提高性能，但也带来了一些问题。  
读放大：LSM-Tree的读操作需要从新到旧(从上到下)一层一层查找，直到找到想要的数据。这个过程可能需要不止一次IO操作。  
空间放大：因为所有的写入都是顺序写(append-only)，不是in-place update，所以过期数据不会马上清理。
写放大：LSM-Tree通过后台Compaction操作来减少读放大(减少SST文件数量)和空间放大(清理过期数据)，但也因此带来了写放大问题，同一份数据会写好多次。

- 问：LSM-Tree和B+ Tree的比较  
答：

- 问：为什么选rocksdb作为flink的状态后端，为啥能支持增量  
答：RocksDB 是由 Facebook 基于 LevelDB 开发的一款提供键值存储与读写功能的 LSM-tree 架构引擎。用户写入的键值对会先写入磁盘上的 WAL (Write Ahead Log)，然后再写入内存中的跳表（SkipList，这部分结构又被称作 MemTable）。LSM-tree 引擎由于将用户的随机修改（插入）转化为了对 WAL 文件的顺序写，因此具有比 B 树类存储引擎更高的写吞吐。而键值的特性和flink的keyed state非常相似，rocksdb本身又比较轻量，非常方便嵌入到其系统之中，因此让其作为状态后端的选择。  
RocksDB的数据存储是一个分层的结构，当memtable写满之后，会将其写入磁盘，成为一个不可变且有序的sstable。Flink会跟踪RocksDB自上一个checkpoint以来创建和删除了哪些sstable文件，将所有新的sstable复制到持久化存储(如HDFS)，之前已经存在的sstable不会复制，而是引用它们，这就是Flink增量checkpoint能够切断历史数据的原因。