---
layout: post
title:  "spark问与答"
author: "marcelyz"
---

之前用spark都是在已有代码上做一些修改，没有系统的认识，在此对spark常见的api及问题做一个梳理。

## 一、常见api
### sql相关
- 常见窗口函数<br/>
答：主要用于解决对一组数据进行操作。主要有三类：排名函数、分析函数和聚合函数。

- row_number().over(Window.partitionBy().orderBy())<br/>
答：row_number()是排名的窗口函数，Window.partitionBy().orderBy()创建一个窗口，使用over来指定窗口函数作用的窗口。

### ml相关
- spark.ml常见算子<br/>
答：

## 二、常见问题
### 概念相关
- RDD、Dataframe、DataSet的区别是什么<br/>
答：RDD：不可变的弹性分布式数据集、非结构化、较底层<br/>
DataFrame：带有schema信息，支持定制的视图和结构；以及方便易用的结构化api，使用Catalyst来生成查询计划，性能上有较大提升。<br/>
DataSet：强类型，在编译时进行类型检测<br/>

- spark任务的提交过程，driver端如何创建dag，dag scheduler的作用，如何分发任务到executor，master和driver的区别<br/>
答：

- 宽窄依赖<br/>
答：

- spark的内存模型，executor的内存划分<br/>
答：
refs: https://iclouding.github.io/2017/05/14/Spark%20%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/
https://zhuanlan.zhihu.com/p/134135758


- Spark Shuffle几种实现方式<br/>
答：

- 存储格式：lzo、orc、parquet、avro区别<br/>
答：

- hive内部表外部表区别<br/>
答：外部表会将数据存储在别处，当删除表的时候，只会删除表的元数据，不会删除真正存储的数据。

- spark streaming/flink流计算中的Exactly-once语义保证<br/>
答：每一条记录只会被正确处理(读取、计算、存储)一次，即使服务器或网络发生故障再重新处理时也能保证没有偏差，即Exactly-once语义。这不仅需要实时计算框架本身的支持，还对上游的消息系统、下游的数据存储有所要求。<br/>
**消息系统**：hdfs天然支持Exactly-once语义，kafka设置在处理流程结束时再提交位点也可以支持；<br/>
**计算流程**：spark中的dag具有容错性、计算不变性等，也能保证该语义；<br/>
**存储**：可通过幂等写入和事务写入支持Exactly-once语义。<br/>
flink：todo

### 算子相关
- reduceByKey和groupByKey的区别<br/>
答：groupByKey先分组后计算，代价较高；reduceByKey先部分计算，再分组聚合，性能较好

- map、flatMap、mapPartitions、mapValues、mapKeys、mapGroups、flatMapGroups的区别<br/>
答：flatMap会对map结果flatten；mapPartitions对分区进行map，map的次数较少；mapValues对value进行操作，mapKeys对key进行操作；mapGroups对group进行操作，通常与groupByKey一起使用；flatMapGroups有flatten的作用。

- mapPartitions、foreachPartition的区别<br/>
答：**返回值区别**：map、mapPartitions属于Transformation操作，延迟触发，返回值一般是rdd/df；foreach、foreachPartition是Action操作，立即触发，返回值一般是数值、object、unit等。<br/>
<font color="#0000ff">使用区别</font>：map系列一般用于链式的转化，对rdd/df做一些惰性变换；foreach系列一般都是在程序末尾比如说要落地数据到存储系统中如mysql，hdfs中使用。

- groupBy、groupByKey的区别<br/>
答：groupBy根据特定列进行分组，多用在ds和df中；groupByKey根据特定key进行分组，多用在rdd中。

- join、joinWith的区别<br/>
答：都是用来join数据的，区别在于返回结果的schema不同，joinWith返回一个嵌套的tuple，保留了原有df的数据类型。

- DStream.transform、DStream.transformWith的区别<br/>
答：都是指在DStream上应用transformFunc方法，返回一个新DStream；区别在于transformWith的入参可以包含其他DStream。

- HashPartitioner和RangePartitioner的区别，如何自定义partitioner，repartition、coalesce的区别<br/>
答：在分区时使用，指定分区的方式。<br/>
HashPartitioner指的是使用Java的Object.hashCode来分区；<br/>
RangePartitioner指的是通过"水塘抽样"算法对Key进行排序，它能保证各个Partition之间的Key是有序的，并且各个Partition之间数据量差不多，但是不保证单个Partition内Key的有序性。<br/>
repartition一般在分区数变多的时候使用，会经过shuffle；coalesce一般在分区数变少的时候使用，不经过shuffle。<br/>

- spark.sql.shuffle.partitions和spark.default.parallelism的区别，分别在什么时候起作用<br/>
答：spark.default.parallelism这个参数只是针对rdd的shuffle操作才生效，spark.sql.shuffle.partitions是对sparkSQL进行shuffle操作(比如窗口函数)的时候生效；这两个参数一般是一起设置成核数的2-3倍。


### 原理相关
- spark join是怎么实现的(sort merge join、broadcast join、hash join)<br/>
答：

- 数据倾斜出现的原因(groupBy倾斜、join倾斜)和对应处理方案<br/>
答：数据倾斜的现象是大部分task执行很快，个别task执行执行极慢，导致程序整体耗时增加。<br/>
原因是在进行shuffle的时候(如distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等)，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行geoupBy聚合或join等操作，如果某个key对应的数据量特别大，task分配不均匀，就会导致数据倾斜。<br/>
处理方案的唯一原则是让各个task的数据量均匀；首先从业务层面上去优化，看能否优化业务逻辑，通过filter等减少shuffle数据量，过滤倾斜key；<br/>
如果实在不能减少，可通过在join/group的key中增加随机key来使shuffle后的数据均匀；如对小表增加一列skew_key，使用explode(lit((0 to n).toArray))扩容n倍；对大表也增加一列skew_key，使用[monotonically_increasing_id() % n]来增加n以内的随机数，n越大，倾斜的数据分配的就越均匀，不过占用的内存也越大。<br/>
refs: https://coxautomotivedatasolutions.github.io/datadriven/spark/data%20skew/joins/data-skew-2/

