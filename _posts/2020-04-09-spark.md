---
layout: post
title:  "spark问与答"
author: "marcelyz"
---

之前用spark都是在已有代码上做一些修改，没有系统的认识，在此对spark常见的api及问题做一个梳理。

## 一、算子相关
- 常见窗口函数<br/>
答：主要用于解决对一组数据进行操作。主要有二类：排序函数(rank/dense_rank/row_number)和聚合函数(max/min/avg/count)。它与group by分组聚合的区别是它不会减少原表中的行数。

- row_number().over(Window.partitionBy().orderBy())<br/>
答：row_number()是排名的窗口函数，Window.partitionBy().orderBy()创建一个窗口，使用orderBy去排序，其中over来指定窗口函数作用的窗口。

- reduceByKey和groupByKey的区别<br/>
答：groupByKey先分组后计算，代价较高；reduceByKey先部分计算，再分组聚合，性能较好

- map、flatMap、mapPartitions、mapValues、mapKeys、mapGroups、flatMapGroups的区别<br/>
答：flatMap会对map结果flatten；mapPartitions对分区进行map，map的次数较少；mapValues对value进行操作，mapKeys对key进行操作；mapGroups对group进行操作，通常与groupByKey一起使用；flatMapGroups有flatten的作用。

- mapPartitions、foreachPartition的区别<br/>
答：**返回值区别**：map、mapPartitions属于Transformation操作，延迟触发，返回值一般是rdd/df；foreach、foreachPartition是Action操作，立即触发，返回值一般是数值、object、unit等。<br/>
<font color="#0000ff">使用区别</font>：map系列一般用于链式的转化，对rdd/df做一些惰性变换；foreach系列一般都是在程序末尾比如说要落地数据到存储系统中如mysql，hdfs中使用。

- 怎么区分Transformation和Action操作<br/>
答：看返回值，Transformation操作一般返回rdd或df类型(如大部分结尾带key的算子)，而action操作一般返回数值、数据结构(如map)或者不返回任何值(如写磁盘)。

- groupBy、groupByKey的区别<br/>
答：groupBy根据特定列进行分组，多用在ds和df中；groupByKey根据特定key进行分组，多用在rdd中。

- join、joinWith的区别<br/>
答：都是用来join数据的，区别在于返回结果的schema不同，joinWith返回一个嵌套的tuple，保留了原有df的数据类型。

- aggregate、treeAggregate的区别<br/>
答：aggregate是在每个分区计算完成后，把所有的数据拉倒driver端，进行统一的遍历合并，这样如果数据量很大，很容易出现单点数据聚合拼劲问题，在driver端可能会OOM；treeAggregate增加了分层树形聚合，启动reduce task对各个map task输出的结果进行两两聚合，然后在聚合后的结果上再进行两两聚合，直至剩余很少的中间聚合结果时，再在driver端进行聚合累加，该算子多用在机器学习的迭代计算梯度中。虽然可以减轻driver端的压力，但是聚合操作的延时会有所增加。

- DStream.transform、DStream.transformWith的区别<br/>
答：都是指在DStream上应用transformFunc方法，返回一个新DStream；区别在于transformWith的入参可以包含其他DStream。

- HashPartitioner和RangePartitioner的区别，如何自定义partitioner，repartition、coalesce的区别<br/>
答：在分区时使用，指定分区的方式。<br/>
HashPartitioner指的是使用Java的Object.hashCode来分区；<br/>
RangePartitioner指的是通过"水塘抽样"算法对Key进行排序，它能保证各个Partition之间的Key是有序的，并且各个Partition之间数据量差不多，但是不保证单个Partition内Key的有序性。<br/>
repartition一般在分区数变多的时候使用，会经过shuffle；coalesce一般在分区数变少的时候使用，默认不经过shuffle，但是有可能有数据倾斜，可以手动指定shuffle。<br/>

- spark.sql.shuffle.partitions和spark.default.parallelism的区别，分别在什么时候起作用<br/>
答：spark.default.parallelism这个参数只是针对rdd的shuffle操作才生效，spark.sql.shuffle.partitions是对sparkSQL进行shuffle操作(比如窗口函数)的时候生效；这两个参数一般是一起设置成核数的2-3倍。


## 二、概念相关
- RDD、Dataframe、DataSet的区别是什么<br/>
答：RDD：不可变的弹性分布式数据集、非结构化、较底层，弹性体现在数据分片repartion；自动进行内存和磁盘的切换；基于血缘关系的高效容错等<br/>
DataFrame：带有schema信息，支持定制的视图和结构；以及方便易用的结构化api，使用Catalyst来生成查询计划，性能上有较大提升。<br/>
DataSet：强类型，在编译时进行类型检测<br/>

- master和driver以及worker和executor的区别；spark任务的提交过程，driver端如何创建dag，dag scheduler的作用，如何分发任务到executor<br/>
答：master和worker都是具体的节点；driver进程可以在任意节点(client、master、worker)，负责构建sparkContext对象、作业的解析，向集群管理者申请资源；executor可以理解为一个进程，持有一个线程池，每个线程执行一个task；master守护进程主要负责与worker的交互。
driver进程会将我们编写的spark应用代码拆分成多个stage，每个stage执行一部分代码片段，并为每个stage创建一批tasks，然后将这些tasks分配到各个executor中执行。
通过一些transformation算子来产生rdd，根据rdd之间的依赖关系来创建dag。

- 宽窄依赖<br/>
答：宽窄依赖表示rdd之间的依赖关系。宽依赖指的是多个子 RDD 的 partition 会依赖同一个 parent RDD的 partition（多子一亲，超生）<br/>
窄依赖指的是每一个 parent RDD 的 partition 最多被子 RDD 的一个 partition 使用（一子一亲，只有一个孩子）<br/>

- Spark shuffle write 和 shuffle read<br/>
答：shuffle机制是指运行在不同stage、不同节点的task间进行数据传递的过程，分为shuffle write和shuffle read两个阶段，前者主要解决上游stage输出数据的分区问题，计算顺序大致为输出->数据聚合->排序->分区，后者主要解决下游stage从上游stage获取数据、重新组织、并为后续操作提供数据的问题，计算顺序大致为数据获取->聚合->排序。在shuffle过程中，聚合操作基于类似HashMap数据结构完成，排序操作基于了类似Array数据结构完成，内存空间不够则spill到磁盘，最后将磁盘和内存中的数据进行聚合、排序，得到最终结果。

- Spark hash base shuffle 和 sort base shuffle<br/>
答：hash和sort是shuffle实现的两种方式，spark初始版本是通过Hash实现的，但是在shuffle时会产生大量文件，这严重制约了spark的性能及扩展能力。因此在后面的版本迭代中产生了sort shuffle方式，它不会为每个task生成一个单独的文件，而是对数据进行排序，然后写到一个数据文件中，同时生成一个索引文件，各个task通过索引文件获取相关的数据。sort模式有三种运行机制，普通运行机制、bypass运行机制、Tungsten sort运行机制，分别对应不同场景下的优化。

- 存储格式：orc、parquet、avro区别<br/>
答：avro是一种基于行的存储格式，编写操作方便。parquet和orc是基于列的存储格式，parquet更能存储嵌套数据；而orc能支持ACID属性，不过orc跟hive接触更紧密，和Impala、presto等查询引擎适配并不好。一般情况下建议使用parquet。

- 压缩算法：lzo、snappy、gzip区别<br/>
答：一般来说说压缩率和压缩速度成反比，这三者压缩率gzip>lzo>snappy，不过gzip是cpu密集型的，对cpu的消耗对比其他算法要高很多。压缩和解压速度snapy>lzo>gzip。

- hive内部表外部表区别<br/>
答：外部表会将数据存储在别处，当删除表的时候，只会删除表的元数据，不会删除真正存储的数据。

- spark streaming/flink流计算中的Exactly-once语义保证<br/>
答：每一条记录只会被正确处理(读取、计算、存储)一次，即使服务器或网络发生故障再重新处理时也能保证没有偏差，即Exactly-once语义。这不仅需要实时计算框架本身的支持，还对上游的消息系统、下游的数据存储有所要求。<br/>
**消息系统**：hdfs天然支持Exactly-once语义，kafka设置在处理流程结束时再提交位点也可以支持；<br/>
**计算流程**：spark中的dag具有容错性、计算不变性等，也能保证该语义；<br/>
**存储**：可通过幂等写入和事务写入支持Exactly-once语义。<br/>
flink：通过checkpoint机制可以保证精准一次；端到端的精准一次需要source和sink本身系统支持，才能保证，一般来说，如果组件支持幂等，或者事务回滚机制，可以通过两阶段提交达到端到端的精准一次语义，比如kafka，mysql，redis等。

- cahce和checkpoint的区别<br/>
答：目的不同，cache是为了增加作业的效率，避免冗余计算。checkpoint是防止数据依赖关系比较复杂的中间数据丢失，使job失败后能够快速恢复。虽然都可以持久化到磁盘，不过一旦driver program执行结束，被cache到磁盘上的RDD就会被清空；而被checkpoint的RDD会一直存在，可以被下一次driver程序使用；但是cache后的rdd能保存dag的血缘关系。

- spark错误容忍机制<br/>
答：核心方法有两种，一是通过dag血缘关系机制来重新执行计算任务。当job抛出异常不能继续执行时，重新启动计算任务，再次执行，容错保证。二是通过checkpoint机制，对一些重要的输入/输出、中间数据进行持久化。这可以在一定程度上解决数据丢失问题，而且能够提高任务重新计算时的效率。


## 三、原理相关
- spark join是怎么实现的<br/>
答：通过Spark hash base shuffle 和 sort base shuffle实现的，broadcast join是通过hash base shuffle来实现的。

- spark物理执行计划生成步骤<br/>
答：spark具体采用3个步骤来生成物理执行计划：首先根据action()操作顺序将应用划分为多个作业job，然后根据每个job的逻辑处理流程中的ShuffleDependency依赖关系，将job划分为多个执行阶段stage。最后在每个stage中，根据最后生成的RDD的分区个数生成多个计算任务task。

- 数据倾斜出现的原因(groupBy倾斜、join倾斜)和对应处理方案<br/>
答：数据倾斜的现象是大部分task执行很快，个别task执行执行极慢，导致程序整体耗时增加。<br/>
原因是在进行shuffle的时候(如distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等)，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行groupBy聚合或join等操作，如果某个key对应的数据量特别大，task分配不均匀，就会导致数据倾斜。<br/>
处理方案的唯一原则是让各个task的数据量均匀；首先从业务层面上去优化，比如对null值进行处理，有时候null值能造成严重的笛卡尔积，数据量暴增；另一方面看能否优化业务逻辑，通过filter等减少shuffle数据量，过滤倾斜key，filter操作完之后记得重分区，不然也会导致不均匀；<br/>
如果实在不能减少，先尽量排查出有倾斜的具体key，然后对这些key进行操作，通过在join/group的keys中新增一列来使shuffle后的数据均匀；如对小表增加一列skew_key，使用explode(lit((0 to n).toArray))扩容n倍；对大表也增加一列skew_key，使用[monotonically_increasing_id() % n]来增加n以内的随机数，两表的n必须相等，这样才能不丢数；n越大，从概率上说倾斜的数据分配的就越均匀，不过占用的内存也越大。<br/>
最后还有一些优化方法，比如只选取必要字段去join，这样shuffle数据占用的内存会大幅度减小，join完之后再反join原始数据，获得其他字段。以及通过业务逻辑转变join key，比如将device join转变成clickid join，缓解数据倾斜。
refs: https://coxautomotivedatasolutions.github.io/datadriven/spark/data%20skew/joins/data-skew-2/

- spark的内存模型，executor的内存划分<br/>
答：spark的内存消耗主要包含3个方面：用户代码(User code)、框架执行(如shuffle write/read中间数据)和数据存储(如cached rdd)。

- spark 3.0 AQE(Adaptive Query Execution，自适应查询执行)<br/>
答：

- spark GC<br/>
答：
