---
layout: post
title:  "spark问与答"
author: "marcelyz"
---

之前用spark都是在已有代码上做一些修改，没有系统的认识，在此对spark常见的api及问题做一个梳理。

## 一、常见api
### sql相关
- 常见窗口函数<br/>
答：主要用于解决对一组数据进行操作，同时为每条数据返回单个结果。主要有三类：排名函数、分析函数和聚合函数。

- row_number().over(Window.partitionBy().orderBy())<br/>
答：row_number()是排名的窗口函数，Window.partitionBy().orderBy()创建一个窗口，使用over来指定窗口函数作用的窗口。

### ml相关
- spark.ml常见算子<br/>
答：

## 二、常见问题
### 概念相关
- RDD、Dataframe、Dataset的区别是什么<br/>
答：

- spark任务的提交过程，driver端如何创建dag，dag scheduler的作用，如何分发任务到executor，master和driver的区别<br/>
答：

- 宽窄依赖<br/>
答：

- spark的内存模型，executor的内存划分<br/>
答：

- Spark Shuffle几种实现方式<br/>
答：

- 存储格式：lzo、orc、parquet、avro、json、csv、txt区别<br/>
答：

- hive内部表外部表区别<br/>
答：外部表会将数据存储在别处，当删除表的时候，只会删除表的元数据，不会删除真正存储的数据。

- spark/flink流计算中的Exactly-once语义保证<br/>
答：


### 算子相关
- reduceByKey和groupByKey的区别<br/>
答：groupByKey先分组后计算，代价较高；reduceByKey先部分计算，再分组聚合，性能较好

- map、flatMap、mapPartitions、mapValues、mapKeys、mapGroups、flatMapGroups的区别<br/>
答：flatMap会对map结果flatten；mapPartitions对分区进行map，map的次数较少；mapValues对value进行操作，mapKeys对key进行操作；mapGroups对group进行操作，通常与groupByKey一起使用；flatMapGroups有flatten的作用。

- groupBy、groupByKey的区别<br/>
答：groupBy根据特定列进行分组，多用在ds和df中；groupByKey根据特定key进行分组，多用在rdd中。

- join、joinWith的区别<br/>
答：都是用来join数据的，区别在于返回结果的schema不同，joinWith返回一个嵌套的tuple，保留了原有df的数据类型。

- DStream.transform、DStream.transformWith的区别<br/>
答：都是指在DStream上应用transformFunc方法，返回一个新DStream；区别在于transformWith的入参可以包含其他DStream。

- HashPartitioner和RangePartitioner的区别，如何自定义partitioner，repartition、coalesce的区别<br/>
答：在分区时使用，指定分区的方式。HashPartitioner指的是使用Java的Object.hashCode来分区；RangePartitioner指的是通过"水塘抽样"算法对Key进行排序，它能保证各个Partition之间的Key是有序的，并且各个Partition之间数据量差不多，但是不保证单个Partition内Key的有序性。

- spark.sql.shuffle.partitions和spark.default.parallelism的区别，分别在什么时候起作用<br/>
答：spark.default.parallelism这个参数只是针对rdd的shuffle操作才生效，spark.sql.shuffle.partitions是对sparkSQL进行shuffle操作(比如窗口函数)的时候生效；这两个参数一般是一起设置成核数的2-3倍。


### 原理相关
- spark join是怎么实现的(sort merge join、broadcast join、hash join)<br/>
答：

- 数据倾斜出现的原因(groupBy倾斜、join倾斜)和对应处理方案<br/>
答：

