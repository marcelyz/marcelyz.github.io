---
layout: post
title:  "kafka问与答"
author: "marcelyz"
---

## 一、原理相关
- 问：kafka怎么保证数据的exactly-once<br/>
答：kafka 0.11.x版本引入了该特性，at least once + 幂等 = exactly once。幂等可以保证单会话单partition内部的exactly-once语义，但是跨partition的exactly-once需要kafka事务来保证，因为kafka可以批量发送消息到多个partition。

- 问：Kafka 高可用如何保证，幂等性如何保证。为什么性能好<br/>
答：通过副本机制保证高可用；通过PID和sequence number序列号保证幂等性，不过PID在应用故障后会被分配一个新的值，所以幂等性无法做到跨会话保证。
通过顺序读写，批量读写压缩，Page Cache操作系统内存，零拷贝，多分区等特性保证高性能。

- 问：offset你们公司如何维护的？为什么不放在mysql<br/>
答：由broker维护，放在一个内置的topic中__consumer_offsets，不用频繁访问zk。

- 问：kafka如何保证数据的单partition有序<br/>
答：单partition是通过write ahead log组织，可以保证FIFO的顺序。在异常触发重试情况下，每个producer会被分配一个PID，对于给定的PID，有一个单调递增的sequence number序列号唯一标识一条msg，在broker接受消息的时候，，会对序列号进行比较，如果producer的序列号比broker的恰好大一，则broker接受它；如果小于等于broker的值，说明是重复消息，丢弃；如果差值比1还大，说明中间有数据没写入，丢弃。

- 问：介绍一下kafka的事务<br/>
答：kafka事务主要是保证多分区批量写入的原子性，要么全部成功，要么全部失败。很容易想到就是2PC两阶段提交，通过一个TransactionCoordinator协调者的角色统计所有参与者的投票结果，大家一致认为可以commit，那就执行commit，否则abort，由Transaction Marker决定；TransactionCoordinator维护事务状态信息transaction log，并把它保存在__transaction_state这个内部topic中，通过副本机制来容错，通过ack机制保证数据一致性。

- 问：订单状态消息乱序怎么办<br>
答：有两种办法，一是从生产端保证，比如将相同的订单id发送到同一个kafka的分区，通过kafka的单分区有序性来保证；二是从业务角度保证，我们这边是通过这种方式的，将订单下所有的状态信息缓存起来，通过规则设置，保证乱序消息不会对业务逻辑造成影响，这样做的好处是鲁棒性比较高，不依赖外部组件。