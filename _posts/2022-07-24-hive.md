---
layout: post
title:  "hive简介"
author: "marcelyz"
---

## 一、原理相关
- **map join怎么做的**  
答：在Map阶段进行表之间的连接。而不需要进入到Reduce阶段才进行连接。这样在Shuffle阶段时就节省了大量的数据传输，起到了优化作业的作用。在map端进行join，其原理是broadcast join，即把小表作为一个完整的驱动表来进行join操作。

- **sql编译过程**  
    1. 语法树解析: Antlr定义SQL的语法规则，完成SQL词法、语法解析，将SQL转化为抽象语法树AST Tree；
    2. 语义解析: 遍历AST Tree，抽象出查询的基本组成单元QueryBlock；
    3. 生成逻辑执行计划: 遍历QueryBlock，翻译为OperatorTree；
    4. 优化逻辑执行计划: 合并Operator减少MapReduce Job数量；谓词下推等；
    5. 生成物理执行计划: 遍历OperatorTree，翻译为MapReduce任务；
    6. 优化物理执行计划: 进行MapReduce任务的变换，分区裁剪，列裁剪，limit优化减少扫描文件数，map端join等优化，生成最终的执行计划。  
<br>

- **count(1)、count(\*)和count(列)的区别**  
答：count(1)和count(*)等价，返回检索到的行的总数，包括null的行。它不会读取表中的数据，而是通过行偏移量来统计的。count(列)返回列非空的行数，会读取该列的数据进行统计。  

- **mapreduce的流程，分为哪几个阶段**    
map：文件split，反序列化，规则转化等。  
map shuffle：Collect、Spill、combine、Merge，在spill阶段会进行分区和排序；combine合并可以减少网络传输，但是仍然需要排序。  
reduce shuffle：Copy、Merge、Sort，在merge-sort阶段同样会进行排序。  
reduce：reduce处理，输出到文件系统。  
<br>

- **spark和mapreduce的shuffle异同**
功能上：MR的shuffle和spark的shuffle是没区别的，都是对Map端的数据进行分区，要么聚合排序，要么不聚合排序，然后Reduce端进行数据拉取，完成map到reduce的数据传输功能。  
方案上：很大的区别，MR的shuffle是基于合并排序的思想，在数据进入reduce之前，都会进行sort，为了方便后续的reduce端的全局排序，而spark的shuffle是可选择的聚合，特别是1.2之后，需要通过调用特定的算子才会触发排序聚合的功能。  
流程上：MR的map端和Reduce区分非常明显，两块涉及到操作也是各司其职，而spark的RDD是内存级的数据转换，不落盘，所以没有明确的划分，只是区分不同的调度阶段，不同的算子模型。  
数据拉取：MR的reduce是直接拉取Map端的分区数据，而spark是根据索引读取，只有在action触发的时候才会去拉取数据。  
<br>