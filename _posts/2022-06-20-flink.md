---
layout: post
title:  "flink问与答"
author: "marcelyz"
---

## 一、算子相关
- 问：在 flink sql 中， join 都包含哪些类型？（引擎层的实现）<br/>
答：在join中包含 Regular join、Interval join、Temporal join、 lookup join；Regular join 包含 left join、right join、 inner join、 full join；Interval join 时间区间 join, 表示两条流之间 一段时间的join.

- 问：window的几种类型<br/>
答：

- 问：Flink状态<br/>
答：状态state是checkpoint产生的数据，

- 问：Flink广播流<br/>
答：

- 问：watermark是干什么的，如何使用<br/>
答：

## 二、概念相关
- 问：flink各种graph的生成逻辑<br/>
答：一共涉及四个graph，StreamGraph、JobGraph、ExecutionGraph和物理执行图；首先在client端根据用户代码生成StreamGraph，表示最初的拓扑结构；然后做一些优化，比如operator chain 等，减少网络shuffle的开销，生成JobGraph，提交给JobManager；JM根据JobGraph生成ExecutionGraph，是用来调度的执行图，可以看作是并行化版本的 JobGraph，将 DAG 拆分到基本的调度单元。最后JobManager根据生成的ExecutionGraph对Job进行调度后，在各个TM上部署Task后形成一张虚拟图，即物理执行图。

- 问：TaskManager主要作用<br/>
答：4大块；1. slot的资源管理，分配与释放；2. task运行，接收来自JM的taks提交，也包括task对应的partition中间结果信息； 3. checkpoint相关的处理； 4. 心跳检测，练级建立等。

- 问：checkpoint的主要流程<br/>
答：1. 首先JobManager会定时触发checkpoint，通过CheckpointCoordinator发送barrier给各Source Operator；
2. 当各个Source Operator接收到来自JM的barrier，会对本地的state进行snapshot操作，完成后以广播的方式发送至下游所有的task；
3. 下游的Operator收到上游发送的barrier后，会停止处理该上游task发送来的record，并等待其他上游发送的barrier，直到接收到所有上游operator发送来的barrier后，会进行当前operator的snapshot动作，成功后通过ack回复JobManager成功；
4. 当JobManager收到所有的Operator的state成功信号后，会记下所有operator对应state的备份数据的地址(state handles)，并将其记载到ZK中，以保证高可用，然后通知所有的task本轮checkpoint成功；
5. 最后JM向所有Operator广播该成功的 CheckpointId，也即调用notifyCheckpointComplete(long checkpointId)；
6. 其中notifyCheckpointComplete和snapshotState是同一个线程(通过打印线程id知道)，但和执行operator的线程不是同一个线程，虽然是在同一个类型中实现，并且notifyCheckpointComplete不算入checkpoint时间。

## 三、原理相关
- 问：checekpoint失败又遇到过吗？原因是啥，怎么解决的<br/>
答：少数情况是因为网络问题，很快能恢复；大部分是因为反压导致，当存在反压时，barrier 需要在 buffer 中流动数个小时，从而导致 checkpoint 执行时间过长，超过了 timeout 还没有完成，从而导致失败。主要通过三个操作缓解，首先一致性语义从exactly-once改成at-least-once，在做checkpoint的过程中，buffer不需要对齐；其次将集群迁移至含有nvme磁盘的机房，对rocksdb有很大优化，ckp稳定性和效率都得到很大提升。最后对join的key做优化，从用户id改成点击id，数据倾斜大幅度缓解，state大小缩小60%。checkpoint耗时从10min缩短为30s左右。

- 问：flink和sparkStreaming的区别<br/>
答：

- 问：flink批处理和实时处理有什么关系<br/>
答：

- 问：Flink精准一次怎么保证<br/>
答：flink引擎本身通过checkpoint机制可以保证精准一次；端到端的精准一次需要source和sink本身系统支持，才能保证，一般来说，如果组件支持幂等，或者事务回滚机制，可以通过两阶段提交达到端到端的精准一次语义，比如kafka，mysql，redis等。

- 问：Flink写入redis怎么保证精准一次<br/>
答：at least once + 幂等 = exactly once；redis天生支持幂等，所以可以通过覆盖写保证精准一次。

- 问：Flink读写kafka怎么保证精准一次<br/>
答：consumer端的Exactly-once语义，通过将offset提交权交给FlinkKafkaConsumer，其内部维护Kafka消费及提交的状态。基于Kafka可重复消费能力并配合Checkpoint机制和状态后端存储能力，就能实现FlinkKafkaConsumer容错性；producer端的Exactly-once语义，通过kafka的事务特性、TwoPhaseCommitSinkFunction和checkpoint机制来保证，2PC(两阶段提交)理论的两个阶段分别对应了FlinkKafkaProducer的状态快照处理阶段和快照结束处理阶段，前者是通过CheckpointedFunction接口的snapshotState方法来初始化Kafka的事务、事务开启、flush等操作预提交事务，并将checkpointId和预提交事务封装成Map存入状态后端中，供恢复使用。后者是通过CheckpointListener接口的notifyCheckpointComplete方法来执行Kafka的commit操作，真正执行事务提交，从而保证producer的不重不丢。
参考：https://blog.51cto.com/u_14222592/2892821; https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html