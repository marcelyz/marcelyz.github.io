---
layout: post
title:  "flink问与答"
author: "marcelyz"
---

## 一、算子相关
- 问：在 flink sql 中， join 都包含哪些类型？（引擎层的实现）<br/>
答：在join中包含 Regular join、Interval join、Temporal join、 lookup join；Regular join 包含 left join、right join、 inner join、 full join；Interval join 时间区间join, 表示两条流之间一段时间的join.

- 问：flink sql的执行流程<br>
答：

- 问：window的几种类型<br/>
答：有两种，一种基于时间(Time-based Window)，包含滑动窗口、滚动窗口、会话窗口；一种基于数量(Count-based Window)，通过数量来卡。每个窗口都包含WindowAssigner、trigger、evictor和Window Function等，Assigner负责确定待处理元素所属的Window；Trigger决定了何时触发计算。Evictor是在用来确定怎么清除数据；Window Function主要分为两种，一种是增量计算，如reduce和aggregate，一种是全量计算，如process。

- 问：Flink状态<br/>
答：状态可以理解为某个算子子任务在其当前实例上的一个变量，记录了数据流的历史信息。当新数据流入时，我们可以结合历史信息来进行计算。举个wordcount的例子，keyby之后的sum算子中实现了一个valuestate，用于存储历史信息中key对应的count，这样就可以不断累加。通过checkpoint操作记录状态的分布式快照信息，同步到持久化存储，当系统异常宕机后，基于ckp信息恢复状态，重新运行。

- 问：Flink广播流<br/>
答：广播流是基于broadcast state的，它就是operator state中的一种mapstate，因为广播流都是双流join的场景，必须要有一个key，因此使用map结构最合适。广播状态流以connect方式共同处理两个事件流。 第一个流的事件被广播到并行的算子中，并且把数据存储到状态中。 另一个流的事件不会被广播，而是发送到同一个算子和程序的各个实例中，并与广播流的事件一起处理，但是不能修改广播状态，而且广播状态是存在jvm的堆内存上的，所以状态后端不能使用rocksdb。在实际场景中，如果遇到需要下发配置、规则等低吞吐事件流到下游所有task时，就可以使用Broadcast State。

- 问：watermark是干什么的，如何使用<br/>
答：可以理解为一个水位线，它是一种衡量Event Time的机制，就是相当于给Event Time事件加上一个可容忍的延迟时间，然后忍这么久再触发窗口计算。水印不会影响原有事件的EventTime，窗口是通过watermark来触发计算的，watermark比事件事件小，表示最大允许延迟到多久，watermark=事件事件-允许延迟时间。这个特别的机制，就是watermark。作用是和window一起处理乱序事件。有两种产生方式，一是标点水位线（Punctuated Watermark），数据流中每一个递增的EventTime都会产生一个Watermark。 二是定期水位线（Periodic Watermark），周期性的（一定时间间隔或者达到一定的记录条数）产生一个Watermark。

## 二、概念相关
- 问：flink各种graph的生成逻辑<br/> 
答：一共涉及四个graph，StreamGraph、JobGraph、ExecutionGraph和物理执行图；首先在client端根据用户代码生成StreamGraph，表示最初的拓扑结构；然后做一些优化，比如operator chain 等，减少网络shuffle的开销，生成JobGraph，提交给JobManager；JM根据JobGraph生成ExecutionGraph，是用来调度的执行图，可以看作是并行化版本的 JobGraph，将 DAG 拆分到基本的调度单元。最后JobManager根据生成的ExecutionGraph对Job进行调度后，在各个TM上部署Task后形成一张虚拟图，即物理执行图。

- 问：TaskManager主要作用<br/>
答：4大块；1. slot的资源管理，分配与释放；2. task运行，接收来自JM的taks提交，也包括task对应的partition中间结果信息； 3. checkpoint相关的处理； 4. 心跳检测，链接建立等。

- 问：checkpoint的主要流程<br/>
答：
1. 首先JobManager会定时触发checkpoint，通过CheckpointCoordinator发送barrier给各Source Operator；
2. 当各个Source Operator接收到来自JM的barrier，会对本地的state进行snapshot操作，完成后以广播的方式发送至下游所有的task；
3. 下游的Operator收到上游发送的barrier后，会停止处理该上游task发送来的record，并等待其他上游发送的barrier，直到接收到所有上游operator发送来的barrier后，会进行当前operator的snapshot动作，成功后通过ack回复JobManager成功；
4. 当JobManager收到所有的Operator的ack信号后，会记下所有operator对应state的备份数据的地址(state handles)，并将其记载到ZK中，以保证高可用，然后通知所有的task本轮checkpoint成功；
5. 最后JM向所有Operator广播该成功的CheckpointId，通知task调用notifyCheckpointComplete(long checkpointId)，做最后提交；
6. 其中notifyCheckpointComplete和snapshotState是同一个线程(通过打印线程id知道)，但和执行operator的线程不是同一个线程，虽然是在同一个类型中实现，并且notifyCheckpointComplete不算入checkpoint时间。

## 三、原理相关
- 问：背压是什么<br/>
答：在流式处理系统中，如果出现下游消费的速度跟不上上游生产数据的速度，就种现象就叫做背压(backpressure)；BackPressure界面会周期性的对Task线程栈信息采样，通过线程被阻塞在请求Buffer的频率来判断节点是否处于背压状态。背压机制类似java中的阻塞队列，通过local bufferpool和network bufferpool协作进行内存申请和释放，同时将内存使用情况实时反馈给上游，实现动态反压。

- 问：checekpoint失败又遇到过吗？原因是啥，怎么解决的<br/>
答：少数情况是因为网络问题，很快能恢复；大部分是因为反压导致，当存在反压时，barrier 需要在 buffer 中流动数个小时，从而导致 checkpoint 执行时间过长，超过了 timeout 还没有完成，从而导致失败。主要通过三个操作缓解，首先一致性语义从exactly-once改成at-least-once，在做checkpoint的过程中，buffer不需要对齐；其次将集群迁移至含有nvme磁盘的机房，对rocksdb有很大优化，ckp稳定性和效率都得到很大提升。最后对join的key做优化，从用户id改成点击id，数据倾斜大幅度缓解，state大小缩小60%。checkpoint耗时从10min缩短为30s左右。

- 问：flink和sparkStreaming的区别<br/>
答：（1）设计理念：spark基于微批，通过rdd进行批量处理，是一种伪实时；flink基于事件驱动，真正的流计算，低延迟。
（2）架构方面：Spark包含Master、Worker、Driver、Executor等；Flink包含Jobmanager、Taskmanager和Slot等。
（3）时间机制：三种时间语义都支持，flink支持更好，本身就是事件驱动。
（4）容错机制：checkpoint容错
（5）吞吐量与延迟：低延迟高吞吐，flink延迟更低，毫秒级。
总结：两者都是基于内存计算，都是高吞吐低延迟。不过流处理flink更优，时间语义、watermark和window等都支持的都比较完善，exactly-once两阶段提交在不同的connector组件上也比较成熟，不过基于flink的tm是在集群启动就开启的进程，任务结束时并不会关闭，所以如果系统不完善的话，可能造成集群metaspace持续增长。批处理spark更优，RDD血缘关系容错，单点故障恢复代价低，不会导致任务全局重启。spark sql优化，性能高。

- 问：flink批处理和流处理有什么关系<br/>
答：批处理基于dataset api，流处理基于datastream api，虽然table和sql api号称流批一体，但是实践较少，不是很稳定，批处理还处于发展阶段吧。

- 问：Flink精准一次怎么保证<br/>
答：flink引擎本身通过checkpoint机制可以保证精准一次；端到端的精准一次需要source和sink本身系统支持，才能保证，一般来说，如果组件支持幂等，或者事务回滚机制，可以通过两阶段提交达到端到端的精准一次语义，比如kafka，mysql，redis等。

- 问：Flink写入redis怎么保证精准一次<br/>
答：at least once + 幂等 = exactly once；redis天生支持幂等，所以可以通过覆盖写保证精准一次。

- 问：Flink读写kafka怎么保证精准一次<br/>
答：consumer端的Exactly-once语义，通过将offset提交权交给FlinkKafkaConsumer，其内部维护Kafka消费及提交的状态。基于Kafka可重复消费能力并配合Checkpoint机制和状态后端存储能力，就能实现FlinkKafkaConsumer容错性；producer端的Exactly-once语义，通过kafka的事务特性、TwoPhaseCommitSinkFunction和checkpoint机制来保证，2PC(两阶段提交)理论的两个阶段分别对应了FlinkKafkaProducer的状态快照处理阶段和快照结束处理阶段，前者是通过CheckpointedFunction接口的snapshotState方法来初始化Kafka的事务、事务开启、flush等操作预提交事务，并将checkpointId和预提交事务封装成Map存入状态后端中，供恢复使用。后者是通过CheckpointListener接口的notifyCheckpointComplete方法来执行Kafka的commit操作，真正执行事务提交，从而保证producer的不重不丢。
参考：https://blog.51cto.com/u_14222592/2892821; https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html