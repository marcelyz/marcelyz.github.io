---
layout: post
title:  "flink问与答"
author: "marcelyz"
---

## 一、算子相关
- 问：在 flink sql 中， join 都包含哪些类型？（引擎层的实现）<br/>
答：在join中包含 Regular join、Interval join、Temporal join、 lookup join；Regular join 包含 left join、right join、 inner join、 full join；Interval join 时间区间join, 表示两条流之间一段时间的join.

- 问：flink sql的执行流程<br>
答：双流join，都是基于state来做的。

- 问：flink数据交换策略Partitioner<br>
答：GlobalPartitioner：分区器会将上游所有元素都发送到下游的第一个算子实例上。
ForwardPartitioner：仅将元素转发到本地运行的下游算子第一个实例。
BroadcastPartitioner：上游算子实例广播发送到下游所有的算子实例上。
ShufflePartitioner：基于正态分布，将数据随机分配到下游各算子实例上。
RebalancePartitioner：使用Round-ribon思想将数据均匀分配到各实例上。Round-ribon轮询是负载均衡领域经常使用的均匀分配的方法。
RescalePartitioner：rescale与rebalance很像，但它的传输开销更小，不是轮询地发送，也是就近发送。
KeyGroupStreamPartitioner：使用 keyBy 函数指定分组 key，将具有相同 key 的元素发送到相同的下游算子。
CustomPartitionerWrapper：自定义实现元素要发送到相对应的下游算子实例。

- 问：window的几种类型<br/>
答：有两种，一种基于时间(Time-based Window)，包含滑动窗口、滚动窗口、会话窗口；一种基于数量(Count-based Window)，通过数量来卡。每个窗口都包含WindowAssigner、trigger、evictor和Window Function等，Assigner负责确定待处理元素所属的Window；Trigger决定了何时触发计算。Evictor是在用来确定怎么清除数据；Window Function主要分为两种，一种是增量计算，如reduce和aggregate，一种是全量计算，如process。

- 问：Flink状态<br/>
答：状态可以理解为某个算子子任务在其当前实例上的一个变量，记录了数据流的历史信息。当新数据流入时，我们可以结合历史信息来进行计算。举个wordcount的例子，keyby之后的sum算子中实现了一个valuestate，用于存储历史信息中key对应的count，这样就可以不断累加。通过checkpoint操作记录状态的分布式快照信息，同步到持久化存储，当系统异常宕机后，基于ckp信息恢复状态，重新运行。  
状态有两种类型，operator state和keyed state，operator state跟一个特定operator实例绑定，以算子并发粒度访问，需要自己实现CheckpointedFunction等方法，通过均匀分配或者合并后分配；而keyed state和具体的key绑定，以单key粒度访问，状态随KeyGroup在算子上重新分配，KeyGroup是key的murmurhash的hashcode对maxParallelism取余，取值范围和maxParallelism一致，进而确定这个key会被分配到那个slot上，所以最大并发度修改后状态无法恢复，一般建议最大并发度是状态算子并发的倍数，这样keygroup会非常均匀。  
operator state包含ListState、UnionListState、BroadCastState。ListState通过均匀划分的方式分配给task；UnionListState将所有state数据合并后再分配给task(kafka connector)。BroadCastState在所有task上都是相同的。  
KeyedState包含ValueState、ListState、MapState等。通过KeyGroup确定key分配的slot，通过key+NameSpace定位一个特定operator的state。

- 问：Flink广播流<br/>
答：广播流是基于broadcast state的，它就是operator state中的一种mapstate，因为广播流都是双流join的场景，必须要有一个key，因此使用map结构最合适。广播状态流以connect方式共同处理两个事件流。 第一个流的事件被广播到并行的算子中，并且把数据存储到状态中。 另一个流的事件不会被广播，而是发送到同一个算子和程序的各个实例中，并与广播流的事件一起处理，但是不能修改广播状态，而且广播状态是存在jvm的堆内存上的，所以状态后端不能使用rocksdb。在实际场景中，如果遇到需要下发配置、规则等低吞吐事件流到下游所有task时，就可以使用Broadcast State。

- 问：watermark是干什么的，如何使用<br/>
答：可以理解为一个水位线，它是一种衡量Event Time的机制，就是相当于给Event Time事件加上一个可容忍的延迟时间，然后忍这么久再触发窗口计算。水印不会影响原有事件的EventTime，窗口是通过watermark来触发计算的，watermark比事件事件小，表示最大允许延迟到多久，watermark=事件事件-允许延迟时间。这个特别的机制，就是watermark。作用是和window一起处理乱序事件。有两种产生方式，一是标点水位线（Punctuated Watermark），数据流中每一个递增的EventTime都会产生一个Watermark。 二是定期水位线（Periodic Watermark），周期性的（一定时间间隔或者达到一定的记录条数）产生一个Watermark。

## 二、概念相关
- 问：flink各种graph的生成逻辑<br/> 
答：一共涉及四个graph，StreamGraph、JobGraph、ExecutionGraph和物理执行图；首先在client端根据用户代码生成StreamGraph，表示最初的拓扑结构；然后做一些优化，比如operator chain 等，减少网络shuffle的开销，生成JobGraph，提交给JobManager；JM根据JobGraph生成ExecutionGraph，是用来调度的执行图，可以看作是并行化版本的 JobGraph，将 DAG 拆分到基本的调度单元。最后JobManager根据生成的ExecutionGraph对Job进行调度后，在各个TM上部署Task后形成一张虚拟图，即物理执行图。

- 问：TaskManager主要作用<br/>
答：4大块；1. slot的资源管理，分配与释放；2. task运行，接收来自JM的taks提交，也包括task对应的partition中间结果信息； 3. checkpoint相关的处理； 4. 心跳检测，链接建立等。

- 问：checkpoint的主要流程<br/>
答：整体是通过chandy-lamport算法保证分布式快照的一致性。
1. 首先JobManager会定时触发checkpoint，通过CheckpointCoordinator发送barrier给各Source Operator；
2. 当各个Source Operator接收到来自JM的barrier，会对本地的state进行snapshot操作，完成后以广播的方式发送至下游所有的task；
3. 下游的Operator收到上游发送的barrier后，会停止处理该上游task发送来的record，并等待其他上游发送的barrier，直到接收到所有上游operator发送来的barrier后，会进行当前operator的snapshot动作，成功后通过ack回复JobManager成功；
4. 当JobManager收到所有的Operator的ack信号后，会记下所有operator对应state的备份数据的地址(state handles)，并将其记载到ZK中，以保证高可用，然后通知所有的task本轮checkpoint成功；
5. 最后JM向所有Operator广播该成功的CheckpointId，通知task调用notifyCheckpointComplete(long checkpointId)，做最后提交；
6. 其中notifyCheckpointComplete和snapshotState是同一个线程(通过打印线程id知道)，但和执行operator的线程不是同一个线程，虽然是在同一个类型中实现，并且notifyCheckpointComplete不算入checkpoint时间。

- 问：flink内存模型<br>
答：TM进程总内存叫Total Process Memory，包含Total Flink Memory + Jvm metaspace + Jvm overhead三部分。
* Total Flink Memory：
    * 堆内存：框架堆内存和task堆内存。使用java代码new出来的对象所占用的内存都存放在堆上，由jvm垃圾回收器维护。
    * 堆外内存：托管内存，直接内存(框架堆外内存，task堆外内存，网络内存)
        * 托管内存(managed memory)：用于排序、哈希表、中间结果缓存、RocksDB backend的本地内存。
        * 直接内存：task堆外内存是flink应用调用native方法时使用的；网络内存(network memory)用于任务之间数据传输的直接内存(例如网络传输缓冲，nio direct buffer)。
* Jvm metaspace：存储类的元数据信息
* Jvm overhead：栈空间、垃圾回收空间等使用的内存

- 问：flink uid是啥，有什么作用  
答：flink使用uid将state映射到operator上，这对与状态恢复至关重要。默认情况下，uid是通过遍历JobGraph并hash特定operator属性来生成运算符uid。尽管对于使用者来说很方便，但是它非常脆弱，因为JobGraph的更改会生成新的uid，为了建立稳定的映射关系，建议必须为算子设置uid。

- 问：简单介绍flink timer  
答：Timer是Flink提供的用于感知并利用处理时间/事件时间变化的机制。最常见的显式利用Timer的地方就是KeyedProcessFunction。我们在其processElement()方法中注册Timer，然后覆写其onTimer()方法作为Timer触发时的回调逻辑。flink中window的Trigger就是基于Timer来设计的。

## 三、原理相关
- 问：背压是什么<br/>
答：在流式处理系统中，如果出现下游消费的速度跟不上上游生产数据的速度，就种现象就叫做背压(backpressure)；BackPressure界面会周期性的对Task线程栈信息采样，通过线程被阻塞在请求Buffer的频率来判断节点是否处于背压状态。背压机制类似java中的阻塞队列，通过local bufferpool和network bufferpool协作进行内存申请和释放，同时将内存使用情况实时反馈给上游，实现动态反压。

- 问：checekpoint失败又遇到过吗？原因是啥，怎么解决的<br/>
答：少数情况是因为网络问题，很快能恢复；大部分是因为反压导致，当存在反压时，barrier 需要在 buffer 中流动数个小时，从而导致 checkpoint 执行时间过长，超过了 timeout 还没有完成，从而导致失败。主要通过三个操作缓解，首先一致性语义从exactly-once改成at-least-once，在做checkpoint的过程中，buffer不需要对齐；其次将集群迁移至含有nvme磁盘的机房，对rocksdb有很大优化，ckp稳定性和效率都得到很大提升。最后对join的key做优化，从用户id改成点击id，数据倾斜大幅度缓解，state大小缩小60%。checkpoint耗时从10min缩短为30s左右。

- 问：flink和sparkStreaming的区别<br/>
答：（1）设计理念：spark基于微批，通过rdd进行批量处理，是一种伪实时；flink基于事件驱动，真正的流计算，低延迟。
（2）架构方面：Spark包含Master、Worker、Driver、Executor等；Flink包含Jobmanager、Taskmanager和Slot等。
（3）时间机制：三种时间语义都支持，flink支持更好，本身就是事件驱动。
（4）容错机制：checkpoint容错
（5）吞吐量与延迟：低延迟高吞吐，flink延迟更低，毫秒级。
总结：两者都是基于内存计算，都是高吞吐低延迟。不过流处理flink更优，时间语义、watermark和window等都支持的都比较完善，exactly-once两阶段提交在不同的connector组件上也比较成熟，不过基于flink的tm是在集群启动就开启的进程，任务结束时并不会关闭，所以如果系统不完善的话，可能造成集群metaspace持续增长。批处理spark更优，RDD血缘关系容错，单点故障恢复代价低，不会导致任务全局重启。spark sql优化，性能高。

- 问：checkpoint和savepoint的区别<br>
答：分别从目标、实现、生命周期三个方面来说。  
首先从目标上讲，checkpoint和savepoint很像传统数据库中的恢复日志和备份日志之间的区别，checkpoint的主要目标是充当flink中的恢复机制，以确保能从潜在的故障中恢复。savepoine的主要目标是充当手动备份之后重启，恢复暂停作业的方法。  
其次从实现上讲，checkpoint的设计轻量且快速。它们可能充分利用底层状态后端的不同功能尽可能快速地恢复数据。如基于rocksdb的状态后端可以利用其内部的分层格式，而不是Flink的原生格式进行增量checkpoint，加速了rocksdb的checkpoint过程。相反，savepoint的设计重点是数据的可移植性，并支持对作业做任何更改，不过这会使数据的生产和恢复成本更高。
最后从生命周期上讲，checkpoint是自动和定期的，他们由flink自动定期地创建和删除，不需要与用户进行交互，以确保在作业意外失败的时候可以恢复。savepoint是由用户手动创建和管理的。

- 问：flink批处理和流处理有什么关系<br/>
答：批处理基于dataset api，流处理基于datastream api，虽然table和sql api号称流批一体，但是实践较少，不是很稳定，批处理还处于发展阶段吧。

- 问：Flink精准一次怎么保证<br/>
答：flink引擎本身通过checkpoint机制可以保证精准一次；端到端的精准一次需要source和sink本身系统支持，才能保证，一般来说，如果组件支持幂等，或者事务回滚机制，可以通过两阶段提交达到端到端的精准一次语义，比如kafka，mysql，redis等。

- 问：Flink写入redis怎么保证精准一次<br/>
答：at least once + 幂等 = exactly once；redis天生支持幂等，所以可以通过覆盖写保证精准一次。

- 问：Flink读写kafka怎么保证精准一次<br/>
答：consumer端的Exactly-once语义，通过将offset提交权交给FlinkKafkaConsumer，其内部维护Kafka消费及提交的状态。基于Kafka可重复消费能力并配合Checkpoint机制和状态后端存储能力，就能实现FlinkKafkaConsumer容错性；producer端的Exactly-once语义，通过kafka的事务特性、TwoPhaseCommitSinkFunction和checkpoint机制来保证，2PC(两阶段提交)理论的两个阶段分别对应了FlinkKafkaProducer的状态快照处理阶段和快照结束处理阶段，前者是通过CheckpointedFunction接口的snapshotState方法来初始化Kafka的事务、事务开启、flush等操作预提交事务，并将checkpointId和预提交事务封装成Map存入状态后端中，供恢复使用。后者是通过CheckpointListener接口的notifyCheckpointComplete方法来执行Kafka的commit操作，真正执行事务提交，从而保证producer的不重不丢。
参考：https://blog.51cto.com/u_14222592/2892821; https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html